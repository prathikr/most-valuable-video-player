{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a470bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = Path(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2faf1339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip2b.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip2a.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip9a.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip10a.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip8d.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip5.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip9b.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip10b.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip10c.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip4.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip8c.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip11c.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip11b.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip8b.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip10d.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip11a.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip8a.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip7b.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip7a.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip6a.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip6b.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip1a.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/action_plays/clip1b.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/1-104089-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/5-218494-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/2-76408-B-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/4-189836-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/1-94036-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/4-205738-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/5-221950-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/3-138114-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip6.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/4-189830-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip7.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip5.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/4-189832-B-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/2-60900-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/5-221567-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/1-115920-B-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip8c.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip4a.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip11b.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip8b.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip1.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/1-110537-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/2-25292-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/2-25293-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/3-197435-B-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip3.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip4c.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip4b.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip11a.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip8a.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/2-76408-D-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip2.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/5-249937-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip12a.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/2-76408-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/5-262957-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip12b.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/5-221568-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/5-254160-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/3-149465-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/3-177083-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/3-177082-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip9.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip13b.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/4-189828-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/1-104089-B-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/3-181278-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip13a.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/5-209989-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/2-76408-C-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip14c.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip14b.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/1-115920-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/1-115921-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip14a.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/3-197435-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/2-57733-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip10.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip15a.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip14d.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/4-189838-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip15b.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/3-130330-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/clip15c.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/1-105224-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/4-189832-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/off_plays/4-189833-A-22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle48.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle74.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip23.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle118.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle60.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle61.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle75.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle119.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle49.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle9.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle88.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle63.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip20.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle77.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip21.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle76.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle62.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle89.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle8.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle99.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle66.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle72.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip25.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip19.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip18.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle73.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip24.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle67.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle98.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip26.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle71.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle65.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle109.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle59.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle58.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle120.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle64.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle108.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip27.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle70.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip6.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle17.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle16.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip7.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip5.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle28.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle14.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle15.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle29.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip4.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle11.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle39.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle38.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle10.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip1.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip3.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle12.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle13.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip2.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle36.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle22.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle23.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle37.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle21.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle35.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle34.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle20.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip9.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle24.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle30.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle18.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle19.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle31.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle25.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip8.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle33.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle27.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle26.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle32.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle3.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle96.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle82.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle69.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle105.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle111.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle55.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip16.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle41.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip17.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle40.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle54.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle110.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle68.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle104.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle83.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle97.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle2.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle81.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle95.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle112.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle106.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle42.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip15.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle56.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle57.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle43.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip14.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle107.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle113.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle94.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle80.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle1.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle5.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle84.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle90.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip10.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle47.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle53.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle117.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle103.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle102.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle116.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle52.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip11.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle46.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle91.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle85.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle4.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle6.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle93.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle87.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle50.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle44.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip13.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle100.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle78.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle114.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle79.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle115.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle101.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle45.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/clip12.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle51.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle86.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle92.wav', '/Users/prathikr/Desktop/most-valuable-video-player/clips/whistles/whistle7.wav']\n"
     ]
    }
   ],
   "source": [
    "action_plays = cwd / \"clips\" / \"action_plays\"\n",
    "off_plays = cwd / \"clips\" / \"off_plays\"\n",
    "whistles = cwd / \"clips\" / \"whistles\"\n",
    "\n",
    "data_dirs = [action_plays, off_plays, whistles]\n",
    "data_files = []\n",
    "\n",
    "for data_dir in data_dirs:    \n",
    "    filenames = [str(data_dir) + \"/\" + f for f in os.listdir(data_dir)]\n",
    "    data_files.extend(filenames)\n",
    "\n",
    "data_files = [item for item in data_files if \".DS_Store\" not in item] # remove .DS_Store file\n",
    "print(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "330224d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 1 44100 1 44100 1 44100 1 44100 1 44100 1 44100 1 44100 1 44100 2 44100 1 44100 2 44100 2 44100 1 44100 1 44100 1 44100 1 44100 2 44100 2 44100 2 44100 2 44100 2 44100 1 44100 1 44100 1 44100 1 44100 2 44100 2 44100 2 44100 2 44100 2 44100 1 44100 2 44100 1 44100 2 44100 1 44100 1 44100 2 44100 1 44100 1 44100 1 44100 1 44100 1 44100 2 44100 2 44100 1 44100 1 44100 1 44100 2 44100 1 44100 1 44100 2 44100 2 44100 1 44100 1 44100 2 44100 1 44100 1 44100 2 44100 2 44100 2 44100 1 44100 2 44100 1 44100 2 44100 1 44100 1 44100 1 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 2 44100 "
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "\n",
    "# check all files have 2 channels and 44.1k sampling rate\n",
    "\n",
    "for file in data_files:\n",
    "    sig, sr = torchaudio.load(file)\n",
    "    print(sig.shape[0], sr, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43187ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "import torch\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "\n",
    "class AudioUtil():\n",
    "    # ----------------------------\n",
    "    # Load an audio file. Return the signal as a tensor and the sample rate\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def open(audio_file):\n",
    "        sig, sr = torchaudio.load(audio_file)\n",
    "        return (sig, sr)\n",
    "            \n",
    "    # ----------------------------\n",
    "    # Convert the given audio to the desired number of channels\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def rechannel(aud, new_channel):\n",
    "        sig, sr = aud\n",
    "\n",
    "        if (sig.shape[0] == new_channel):\n",
    "            # Nothing to do\n",
    "            return aud\n",
    "\n",
    "        if (new_channel == 1):\n",
    "            # Convert from stereo to mono by selecting only the first channel\n",
    "            resig = sig[:1, :]\n",
    "        else:\n",
    "            # Convert from mono to stereo by duplicating the first channel\n",
    "            resig = torch.cat([sig, sig])\n",
    "\n",
    "        return ((resig, sr))\n",
    "\n",
    "    # ----------------------------\n",
    "    # Pad (or truncate) the signal to a fixed length 'max_ms' in milliseconds\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def pad_trunc(aud, max_ms):\n",
    "        sig, sr = aud\n",
    "        num_rows, sig_len = sig.shape\n",
    "        max_len = sr//1000 * max_ms\n",
    "\n",
    "        if (sig_len > max_len):\n",
    "            # Truncate the signal to the given length\n",
    "            sig = sig[:,:max_len]\n",
    "\n",
    "        elif (sig_len < max_len):\n",
    "            # Length of padding to add at the beginning and end of the signal\n",
    "            pad_begin_len = random.randint(0, max_len - sig_len)\n",
    "            pad_end_len = max_len - sig_len - pad_begin_len\n",
    "\n",
    "            # Pad with 0s\n",
    "            pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
    "            pad_end = torch.zeros((num_rows, pad_end_len))\n",
    "\n",
    "            sig = torch.cat((pad_begin, sig, pad_end), 1)\n",
    "\n",
    "        return (sig, sr)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Shifts the signal to the left or right by some percent. Values at the end\n",
    "    # are 'wrapped around' to the start of the transformed signal.\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def time_shift(aud, shift_limit):\n",
    "        sig,sr = aud\n",
    "        _, sig_len = sig.shape\n",
    "        shift_amt = int(random.random() * shift_limit * sig_len)\n",
    "        return (sig.roll(shift_amt), sr)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Generate a Spectrogram\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
    "        sig,sr = aud\n",
    "        top_db = 80\n",
    "\n",
    "        # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "        spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "\n",
    "        # Convert to decibels\n",
    "        spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "        return (spec)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Augment the Spectrogram by masking out some sections of it in both the frequency\n",
    "    # dimension (ie. horizontal bars) and the time dimension (vertical bars) to prevent\n",
    "    # overfitting and to help the model generalise better. The masked sections are\n",
    "    # replaced with the mean value.\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
    "        _, n_mels, n_steps = spec.shape\n",
    "        mask_value = spec.mean()\n",
    "        aug_spec = spec\n",
    "\n",
    "        freq_mask_param = max_mask_pct * n_mels\n",
    "        for _ in range(n_freq_masks):\n",
    "            aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "        time_mask_param = max_mask_pct * n_steps\n",
    "        for _ in range(n_time_masks):\n",
    "            aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "        return aug_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d3fc060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "# ----------------------------\n",
    "# Sound Dataset\n",
    "# ----------------------------\n",
    "class SoundDS(Dataset):\n",
    "    def __init__(self, data_files):\n",
    "        self.data_files = data_files\n",
    "        self.duration = 5000\n",
    "        self.sr = 44100\n",
    "        self.channel = 2\n",
    "        self.shift_pct = 0.4\n",
    "\n",
    "    # ----------------------------\n",
    "    # Number of items in dataset\n",
    "    # ----------------------------\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)    \n",
    "\n",
    "    # ----------------------------\n",
    "    # Get i'th item in dataset\n",
    "    # ----------------------------\n",
    "    def __getitem__(self, idx):\n",
    "        # Absolute file path of the audio file - concatenate the audio directory with\n",
    "        # the relative path\n",
    "        audio_file = self.data_files[idx]\n",
    "        # Get the Class ID\n",
    "        class_id = -1\n",
    "        if \"whistle\" in audio_file:\n",
    "            class_id = 0\n",
    "        elif \"action_play\" in audio_file:\n",
    "            class_id = 1\n",
    "        elif \"off_play\" in audio_file:\n",
    "            class_id = 2\n",
    "\n",
    "        aud = AudioUtil.open(audio_file)\n",
    "\n",
    "        rechan = AudioUtil.rechannel(aud, self.channel)\n",
    "        dur_aud = AudioUtil.pad_trunc(rechan, self.duration)\n",
    "        shift_aud = AudioUtil.time_shift(dur_aud, self.shift_pct)\n",
    "        sgram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "        aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "\n",
    "        return aug_sgram, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "296d7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "myds = SoundDS(data_files)\n",
    "\n",
    "# Random split of 80:20 between training and validation\n",
    "num_items = len(myds)\n",
    "num_train = round(num_items * 0.8)\n",
    "num_val = num_items - num_train\n",
    "train_ds, val_ds = random_split(myds, [num_train, num_val])\n",
    "\n",
    "# Create training and validation data loaders\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c634c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting hardware backend...\n",
      "mps backend set\n"
     ]
    }
   ],
   "source": [
    "print(\"setting hardware backend...\")\n",
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device=torch.device('mps')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "print(f\"{device} backend set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ffd57a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import torch.nn as nn\n",
    "\n",
    "# ----------------------------\n",
    "# Audio Classification Model\n",
    "# ----------------------------\n",
    "class AudioClassifier (nn.Module):\n",
    "    # ----------------------------\n",
    "    # Build the model architecture\n",
    "    # ----------------------------\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        conv_layers = []\n",
    "\n",
    "        # First Convolution Block with Relu and Batch Norm. Use Kaiming Initialization\n",
    "        self.conv1 = nn.Conv2d(2, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        init.kaiming_normal_(self.conv1.weight, a=0.1)\n",
    "        self.conv1.bias.data.zero_()\n",
    "        conv_layers += [self.conv1, self.relu1, self.bn1]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        init.kaiming_normal_(self.conv2.weight, a=0.1)\n",
    "        self.conv2.bias.data.zero_()\n",
    "        conv_layers += [self.conv2, self.relu2, self.bn2]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        init.kaiming_normal_(self.conv3.weight, a=0.1)\n",
    "        self.conv3.bias.data.zero_()\n",
    "        conv_layers += [self.conv3, self.relu3, self.bn3]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        init.kaiming_normal_(self.conv4.weight, a=0.1)\n",
    "        self.conv4.bias.data.zero_()\n",
    "        conv_layers += [self.conv4, self.relu4, self.bn4]\n",
    "\n",
    "        # Linear Classifier\n",
    "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.lin = nn.Linear(in_features=64, out_features=3)\n",
    "\n",
    "        # Wrap the Convolutional Blocks\n",
    "        self.conv = nn.Sequential(*conv_layers)\n",
    " \n",
    "    # ----------------------------\n",
    "    # Forward pass computations\n",
    "    # ----------------------------\n",
    "    def forward(self, x):\n",
    "        # Run the convolutional blocks\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # Adaptive pool and flatten for input to linear layer\n",
    "        x = self.ap(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        print(x.shape)\n",
    "        # Linear layer\n",
    "        x = self.lin(x)\n",
    "        x = nn.functional.softmax(x, dim=1)\n",
    "\n",
    "        # Final output\n",
    "        return x\n",
    "\n",
    "# Create the model and put it on the GPU if available\n",
    "myModel = AudioClassifier()\n",
    "myModel = myModel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4249329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([14, 64])\n",
      "Epoch: 0, Loss: 1.10, Accuracy: 0.36\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([14, 64])\n",
      "Epoch: 1, Loss: 1.07, Accuracy: 0.53\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([14, 64])\n",
      "Epoch: 2, Loss: 1.03, Accuracy: 0.65\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([14, 64])\n",
      "Epoch: 3, Loss: 0.97, Accuracy: 0.74\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([14, 64])\n",
      "Epoch: 4, Loss: 0.93, Accuracy: 0.73\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([14, 64])\n",
      "Epoch: 5, Loss: 0.86, Accuracy: 0.78\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n",
      "torch.Size([16, 64])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished Training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     55\u001b[0m num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m   \u001b[38;5;66;03m# Just for demo, adjust this higher.\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmyModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [9], line 20\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, train_dl, num_epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m total_prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Repeat for each batch in the training set\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dl):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Get the input features and target labels, and put them on the GPU\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Normalize the inputs\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/Stanford_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniforge3/envs/Stanford_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/Stanford_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniforge3/envs/Stanford_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniforge3/envs/Stanford_env/lib/python3.10/site-packages/torch/utils/data/dataset.py:295\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn [5], line 36\u001b[0m, in \u001b[0;36mSoundDS.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff_play\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m audio_file:\n\u001b[1;32m     34\u001b[0m     class_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 36\u001b[0m aud \u001b[38;5;241m=\u001b[39m \u001b[43mAudioUtil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m rechan \u001b[38;5;241m=\u001b[39m AudioUtil\u001b[38;5;241m.\u001b[39mrechannel(aud, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel)\n\u001b[1;32m     39\u001b[0m dur_aud \u001b[38;5;241m=\u001b[39m AudioUtil\u001b[38;5;241m.\u001b[39mpad_trunc(rechan, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration)\n",
      "Cell \u001b[0;32mIn [4], line 12\u001b[0m, in \u001b[0;36mAudioUtil.open\u001b[0;34m(audio_file)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(audio_file):\n\u001b[0;32m---> 12\u001b[0m     sig, sr \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (sig, sr)\n",
      "File \u001b[0;32m~/miniforge3/envs/Stanford_env/lib/python3.10/site-packages/torchaudio/backend/sox_io_backend.py:222\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _fallback_load_fileobj(filepath, frame_offset, num_frames, normalize, channels_first, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m    221\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(filepath)\n\u001b[0;32m--> 222\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msox_io_load_audio_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\n\u001b[1;32m    224\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/miniforge3/envs/Stanford_env/lib/python3.10/site-packages/torch/_ops.py:442\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Training Loop\n",
    "# ----------------------------\n",
    "def training(model, train_dl, num_epochs):\n",
    "    # Loss Function, Optimizer and Scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                            steps_per_epoch=int(len(train_dl)),\n",
    "                            epochs=num_epochs,\n",
    "                            anneal_strategy='linear')\n",
    "\n",
    "    # Repeat for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_prediction = 0\n",
    "        total_prediction = 0\n",
    "\n",
    "        # Repeat for each batch in the training set\n",
    "        for i, data in enumerate(train_dl):\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Keep stats for Loss and Accuracy\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "\n",
    "        # Print stats at the end of the epoch\n",
    "        num_batches = len(train_dl)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        acc = correct_prediction/total_prediction\n",
    "        print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "num_epochs=25   # Just for demo, adjust this higher.\n",
    "training(myModel, train_dl, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602dac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aud0 = AudioUtil.open(\"/Users/prathikr/Desktop/volleyball-audio-data/clips/whistles/clip12.wav\") # class 0\n",
    "aud1 = AudioUtil.open(\"/Users/prathikr/Desktop/volleyball-audio-data/clips/action_plays/clip2b.wav\") # class 1\n",
    "aud2 = AudioUtil.open(\"/Users/prathikr/Desktop/volleyball-audio-data/clips/off_plays/clip9.wav\") # class 2\n",
    "\n",
    "dur_aud0 = AudioUtil.pad_trunc(aud0, 5000)\n",
    "shift_aud0 = AudioUtil.time_shift(dur_aud0, 0.4)\n",
    "sgram0 = AudioUtil.spectro_gram(shift_aud0, n_mels=64, n_fft=1024, hop_len=None)\n",
    "aug_sgram0 = AudioUtil.spectro_augment(sgram0, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "\n",
    "dur_aud1 = AudioUtil.pad_trunc(aud1, 5000)\n",
    "shift_aud1 = AudioUtil.time_shift(dur_aud1, 0.4)\n",
    "sgram1 = AudioUtil.spectro_gram(shift_aud1, n_mels=64, n_fft=1024, hop_len=None)\n",
    "aug_sgram1 = AudioUtil.spectro_augment(sgram1, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "\n",
    "dur_aud2 = AudioUtil.pad_trunc(aud2, 5000)\n",
    "shift_aud2 = AudioUtil.time_shift(dur_aud2, 0.4)\n",
    "sgram2 = AudioUtil.spectro_gram(shift_aud2, n_mels=64, n_fft=1024, hop_len=None)\n",
    "aug_sgram2 = AudioUtil.spectro_augment(sgram2, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "\n",
    "test_dl = torch.utils.data.DataLoader([aug_sgram0, aug_sgram1, aug_sgram2], batch_size=3, shuffle=False)\n",
    "\n",
    "# Get predictions\n",
    "for test in test_dl:\n",
    "    test = test.to(device)\n",
    "    outputs = myModel(test)\n",
    "    # Get the predicted class with the highest score\n",
    "    _, prediction = torch.max(outputs,1)\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a67ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Inference\n",
    "# ----------------------------\n",
    "def inference (model, val_dl):\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "\n",
    "    # Disable gradient updates\n",
    "    with torch.no_grad():\n",
    "        for data in val_dl:\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            # Get predictions\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            print(\"prediction:\", prediction)\n",
    "            print(\"labels:    \", labels)\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "\n",
    "    acc = correct_prediction/total_prediction\n",
    "    print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')\n",
    "\n",
    "# Run inference on trained model with the validation set\n",
    "inference(myModel, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3807de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "output_dir = cwd / \"tmp\"\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "os.makedirs(output_dir)\n",
    "\n",
    "myaudio = AudioSegment.from_file(\"los-altos-comeback.wav\" , \"wav\") \n",
    "chunk_length_ms = 2500 # pydub calculates in millisec\n",
    "chunks = make_chunks(myaudio, chunk_length_ms) #Make chunks of one sec\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk_name = \"chunk{0}.wav\".format(i)\n",
    "    chunk.export(output_dir / chunk_name, format=\"wav\")\n",
    "\n",
    "mypath = \"tmp/\"\n",
    "chunk_files = [os.path.join(dirpath,f) for (dirpath, dirnames, filenames) in os.walk(mypath) for f in filenames]\n",
    "chunk_files.sort(key=lambda test_string : list(map(int, re.findall(r'\\d+', test_string)))[0]) # sort by chunk number\n",
    "print(chunk_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5256c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "\n",
    "for data_file in chunk_files:\n",
    "    full_path = cwd / data_file\n",
    "    aud = AudioUtil.open(full_path)\n",
    "\n",
    "    dur_aud = AudioUtil.pad_trunc(aud, 5000)\n",
    "    shift_aud = AudioUtil.time_shift(dur_aud, 0.4)\n",
    "    sgram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "    aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "    test_data.append(aug_sgram)\n",
    "    \n",
    "test_dl = torch.utils.data.DataLoader(test_data, batch_size=16, shuffle=False)\n",
    "# Get predictions\n",
    "for i, data in enumerate(test_dl):\n",
    "    inputs = data.to(device)\n",
    "    \n",
    "    # Normalize the inputs\n",
    "    inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "    inputs = (inputs - inputs_m) / inputs_s\n",
    "        \n",
    "    outputs = myModel(inputs)\n",
    "    # Get the predicted class with the highest score\n",
    "    _, prediction = torch.max(outputs,1)\n",
    "    print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8998d804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
